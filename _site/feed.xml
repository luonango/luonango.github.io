<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BY Blog</title>
    <description>Every failure is leading towards success.</description>
    <link>http://luonango.github.io/</link>
    <atom:link href="http://luonango.github.io/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sat, 06 Oct 2018 11:37:16 +0800</pubDate>
    <lastBuildDate>Sat, 06 Oct 2018 11:37:16 +0800</lastBuildDate>
    <generator>Jekyll v3.0.1</generator>
    
      <item>
        <title>Fusedmax与Oscarmax</title>
        <description>&lt;h1 id=&quot;fusedmaxoscarmaxattention&quot;&gt;2017_Fusedmax与Oscarmax_稀疏及结构化的Attention正则化框架&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2017_NIPS
康奈尔大学, Vlad Niculae
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;论文提出&lt;strong&gt;让Attention输出稀疏&lt;/strong&gt;且更关注&lt;strong&gt;输入数据的片段或组&lt;/strong&gt;的正则化机制，它还能直接加入神经网络进行前向与反向传播。&lt;/p&gt;

&lt;p&gt;论文地址: &lt;a href=&quot;https://papers.nips.cc/paper/6926-a-regularized-framework-for-sparse-and-structured-neural-attention.pdf&quot;&gt;A Regularized Framework for Sparse and Structured Neural Attention&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;1. 简单介绍:&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Attention的关键是映射函数&lt;/strong&gt;，它对输入元素的相对重要性进行编码，将数值映射为概率。而常用的关注机制&lt;strong&gt;Softmax会产生密集的注意力&lt;/strong&gt;。因为softmax的输出都大于0，故其输入的所有元素对最终决策都有或多或少的影响。&lt;/p&gt;

&lt;p&gt;为了克服softmax这种缺点，&lt;a href=&quot;https://arxiv.org/pdf/1602.02068.pdf&quot;&gt;From Softmax to Sparsemax:A Sparse Model of Attention and Multi-Label Classification&lt;/a&gt; 提出了能够&lt;strong&gt;输出稀疏概率的Sparsemax&lt;/strong&gt;，这能为Attention提供更多的解释性。&lt;/p&gt;

&lt;p&gt;本文基于Sparsemax，提出的方法既可以得到稀疏的输出，又可以作为一个诱导稀疏的惩罚模型，可作用于当前的其他模型上。 本文提出的通用框架是&lt;strong&gt;建立在$\max$运算符上的，采用强凸（strong convex）函数进行调整后得到的算子是可微的，它的梯度定义了从输入数值到概率的映射，适合作为Attention机制&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;基于fused lasso提出了&lt;strong&gt;Fusedmax鼓励网络对连续区域（或说文本段）的Attention值相同&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;限定连续区域的Attention值相同的假设太严苛，文中又基于oscar提出&lt;strong&gt;Oscarmax的关注机制，鼓励网络对不连续的单词组的Attention值相同&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上述只是文章简单概括。 疑问有很多，比如：建立在$\max$算子是什么意思？强凸函数怎么调整？梯度定义了映射函数？Fusedmax和Oscarmax又是怎么做到的？&lt;/p&gt;

&lt;p&gt;那下面就一步步解释文章思路。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;## 2. 论文的思路:&lt;/p&gt;

&lt;p&gt;先给出一些定义：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;集合${1,2,…,d}$定义为$[d]$，$d-1$维的单形体为$\Delta^d:={x\in R^d:\mid\mid x\mid\mid_1=1,x \geq0}$， 在欧几里得的投影为$P_{\Delta^d}(x):={\arg\min}_{y\in \Delta^d}\mid\mid y-x\mid\mid^2$&lt;/li&gt;
  &lt;li&gt;如果函数$f:R^d\rightarrow R\bigcup {\infty}$, 则其凸共轭(convex conjugate)为$f^{&lt;em&gt;}(x):=\sup_{y\in dom\;f}y^Tx-f(y)$.  给定范数$\mid\mid\cdot\mid\mid$,它的对偶定义为$\mid\mid x\mid\mid_&lt;/em&gt; :=\sup_{\mid\mid y\mid\mid \leq 1}y^T x$. 用$\partial f(y)$ 表示函数$f$在$y$处的次微分 &lt;br /&gt;
&amp;gt; 次微分subdifferential,凸函数$f(x)=\mid x\mid$在原点的次微分是区间$[−1, 1]$.&lt;/li&gt;
  &lt;li&gt;函数$f$的Jacobian(雅可比)$J_{g}(y)\in R^{d\times d}$,Hessian(海森矩阵)$H_{f}(y)\in R^{d\times d}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;现在我们看下$max$算子（虽然是$R^d \rightarrow \Delta^d$的映射函数，但不适合作为Attention机制):&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\max(x):=\max_{i\in [d]} x_i = \sup_{y\in \Delta^d} y^Tx&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;由于在单形体的线性上确界总是顶点，也即为标准基向量${e_i}^d_{i=1}$的其中之一。 这也容易看出这个上确界$y^&lt;em&gt;$ 就是$\max(x)$的一个次梯度$\partial \max(x) ={e_{i^&lt;/em&gt;} : i^* \in \arg\max_{i\in [d]} x_i}$.&lt;/p&gt;

&lt;p&gt;我们将这些次梯度看作一种映射：$\prod:R^d \rightarrow \Delta^d$,它将所有的概率质量都放在一个元素上(即$\max$操作只有一个元素获得非0输出):$\prod(x) = e_i,\; for \;any\; e_i \in \partial \max(x)$.&lt;/p&gt;

&lt;p&gt;因为这映射函数不连续（存在阶跃断点），这不适合通过梯度下降法进行优化,显然这种属性我们是不希望的.&lt;/p&gt;

&lt;p&gt;从这可以看出，$\max(x)$的次梯度$y^*$是$\prod:R^d \rightarrow \Delta^d$映射，&lt;strong&gt;如果$\max(x)$的变种函数是连续可二次微分，那$y^&lt;em&gt;$也就可以用作Attention，且也能够让梯度下降方法进行优化了（梯度为$y^&lt;/em&gt;$的导数）&lt;/strong&gt;。&lt;br /&gt;
&amp;gt;注意，此处$\prod(x)$也表示Attention的输出，如果$\prod(x)$可导，就可以嵌入普通神经网络进行梯度下降优化了。&lt;/p&gt;

&lt;p&gt;受到&lt;a href=&quot;http://luthuli.cs.uiuc.edu/~daf/courses/optimization/MRFpapers/nesterov05.pdf&quot;&gt;Y.Nesterov. Smooth minimization of non-smooth functions&lt;/a&gt;的启发,本文运用了Smooth技术. 对于$\max(x)$的共轭函数${\max}^&lt;em&gt;(y)$:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
{\max}^*(y)=\left\{
             \begin{array}{l}
             0, &amp; if\; y\in \Delta^d \\
             \infty, &amp; o.w. 
             \end{array}\right. %]]&gt;&lt;/script&gt; &lt;br /&gt;
&amp;gt;该共轭函数的证明在&lt;a href=&quot;http://papers.nips.cc/paper/5710-smooth-and-strong-map-inference-with-linear-convergence&quot;&gt;Smooth and strong: MAP inference with linear&lt;br /&gt;
convergence, Appendix B&lt;/a&gt; 中。其实通过求解共轭函数的方法就可以得解：$max^&lt;/em&gt;(y)=\sup(y^Tx-\sup z^Tx)$, 对$x$求偏导得$y^&lt;em&gt;=z^&lt;/em&gt;$再带入原式即可。&lt;/p&gt;

&lt;p&gt;那现在将正则化添加到共轭函数中：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
{\max}^*_{\Omega}(y)=\left\{
             \begin{array}{l}
             \gamma\Omega(y), &amp; if\; y\in \Delta^d \\
             \infty, &amp; o.w. 
             \end{array}\right. %]]&gt;&lt;/script&gt; &lt;br /&gt;
其中假设函数$\Omega:R^d\rightarrow R$是关于norm $\mid\mid\cdot\mid\mid$的&lt;strong&gt;$\beta$-strongly convex&lt;/strong&gt;($\beta强凸$)。$\gamma$ 控制着正则强度。&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;参考&lt;a href=&quot;https://cswhjiang.github.io/2015/04/08/strong-convexity-and-smoothness/&quot;&gt;Strong Convexity and Smoothness&lt;/a&gt;：&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;函数$f$是 $\alpha$-strong convex($\alpha &amp;gt; 0$)需要满足条件：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;f(y)-f(x)\geq \nabla f(x)^T(y-x) + \frac{\alpha}{2}\mid\mid y-x \mid\mid^2_P&lt;/script&gt;&lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;如果一个连续可微的函数$f$的梯度$\nabla f(x)$是$\beta$-Lipschitz的，即：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\mid\mid\nabla f(x)-\nabla f(y)\mid\mid \leq\beta\mid\mid x-y\mid\mid,&lt;/script&gt;&lt;br /&gt;
那么我们称 $f(x)$ 是$\beta$-smooth的,更一般表示为：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\mid\mid\nabla f(x)-\nabla f(y)\mid\mid_D \leq\beta\mid\mid x-y\mid\mid_P,&lt;/script&gt;&lt;br /&gt;
其中$\mid\mid\cdot\mid\mid_P$是范数norm，$\mid\mid\cdot\mid\mid_D$是对偶范数dual norm。&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;函数的$\alpha$-strongly convex和 $\beta$-smoothness有对偶关系，如果函数$f$是关于对偶范数 $\mid\mid\cdot\mid\mid_D$ 的$\beta$-smooth,那么$f^&lt;em&gt;$是关于范数$\mid\mid\cdot\mid\mid_P$的$\frac{1}{\beta}$-strongly convex。 其中$f^&lt;/em&gt;=\max_y(y^Tx-f(y))$是函数$f(x)$的共轭函数。&lt;/li&gt;
  &lt;/ul&gt;

  &lt;p&gt;Wiki中也可以查阅详细定义与解释。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了定义出平滑的$\max$算子: $\max_{\Omega}$，再次使用共轭：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{\max}_{\Omega}(x)=max_{\Omega}^{**}(x) = \sup_{y\in R^d} y^Tx - {\max}^*_{\Omega} (y)=\sup_{y\in\Delta^d}y^Tx-\gamma\Omega(y)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;由此，前面提到的映射${\prod}&lt;em&gt;{\Omega}: R^d\rightarrow \Delta^d$定义为：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{\prod}_{\Omega}(x):=\arg\max_{y\in \Delta^d}y^Tx-\gamma\Omega(y)=\nabla max_{\Omega}(x)&lt;/script&gt;&lt;br /&gt;
&amp;gt; 1. 上述式子可由：$\max&lt;/em&gt;{\Omega}(x)=(y^&lt;em&gt;)^Tx-\max^&lt;/em&gt;&lt;em&gt;{\Omega}(y^*)\Longleftrightarrow y^* \in \partial\max&lt;/em&gt;{\Omega}(x)$ 证得。&lt;br /&gt;
&amp;gt; 2. $\partial\max_{\Omega}(x)={\nabla\max_{\Omega}(x)}$只有唯一解（$y^*$是单形体的顶点）。故$\prod_{\Omega}$ 是梯度的映射函数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;强凸的重要性：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对$\Omega$的$\beta$-strongly convex的假设是很重要的，如果函数$f:R^d\rightarrow R$ 的共轭函数 $f^*$ 是关于对偶范数 $\mid\mid\cdot\mid\mid_D$ 的$\frac{1}{\beta}$-smooth, 那么 $f$ 就是关于范数 $\mid\mid\cdot\mid\mid_P$ 的 $\beta$-strongly convex。那么这足以确保 $\max_{\Omega}$是$\frac{1}{\gamma\beta}$-smooth, 或者说 $\max_{\Omega}$ 处处可微，且它的梯度 $\prod_{\Omega}$ 在对偶范数 $\mid\mid\cdot\mid\mid_D$上是 $\frac{1}{\gamma\beta}$-Lipschitz的.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;训练问题（$\prod_{\Omega}$即表示Attention的输出）：&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;前向时，需要解决的问题是：如何计算 $\prod_{\Omega}$ ?&lt;/li&gt;
  &lt;li&gt;反向时，需要解决的问题是：如何计算 $\prod_{\Omega}$ 的雅可比矩阵？或说如何计算 $\max_{\Omega}$ 的Hessian矩阵？&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;## 3. 验证方法：用正则项 $\Omega$恢复Softmax与Sparsemax&lt;/p&gt;

&lt;p&gt;在推导新的Attention机制前，先展示如何用正则项$\Omega$恢复出softmax和sparsemax。&lt;/p&gt;

&lt;h3 id=&quot;softmax&quot;&gt;3.1 Softmax：&lt;/h3&gt;

&lt;p&gt;选择$\Omega(y)=\sum_{i=1}^d y_i \log y_i$ ,即负熵。则它的共轭函数为 $log\;sum\;exp$, 即$f^*(y)=\log \sum_{i=1}^d e^{y_i}$.&lt;br /&gt;
&amp;gt;证明此时$\Omega(y)$的共轭函数为 $log\;sum\;exp$ :&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;若函数 $f(x)=\log \sum_{i=1}^n e^{x_i}$ ,则由$f^*(y)=sup y^Tx-f(x)$ 对$x$求偏导得：$y_i=\frac{e^{x_i}}{\sum_{i=1}^n e^{x_i}}$ , 即$1^Ty=1,\sum y_i =1$.&lt;/p&gt;

  &lt;p&gt;故有$e^{x_i}=y_i\sum e^{x_i} \Rightarrow$&lt;/p&gt;

  &lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{array}{l}
f^*(y) &amp; =\sum y_i x_i - log\sum e^{x_i} \\
&amp; =\sum y_i \log(y_i\sum e^{x_i})-\log\sum e^{x_i} \\
&amp; = \sum y_i\log y_i + \sum y_i \log\sum e^{x_i}-\log\sum e^{x_i} \\
&amp; = \sum y_i\log y_i
\end{array} %]]&gt;&lt;/script&gt;&lt;br /&gt;
由于$f(x)$是凸函数（可证），所以$f^{**}=log\;sum\;exp$.&lt;br /&gt;
也可以查阅&lt;a href=&quot;https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf&quot;&gt;《Convex optimization》&lt;/a&gt;的习题3.25, 里面有详细证明。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;如果 $f(x)=\gamma g(x)$,则对于 $\gamma &amp;gt;0$,有 $f^&lt;em&gt;(y)=\gamma g^&lt;/em&gt;(y/\gamma)$. 则${\max}&lt;em&gt;{\Omega}(x)=\gamma \log\sum&lt;/em&gt;{i=1}^d e^{x_i / \gamma}$.&lt;/p&gt;

&lt;p&gt;由于$\Omega(y)$负熵在 $\mid\mid\cdot\mid\mid_1$ 是 1-strongly convex，所以${\max}&lt;em&gt;{\Omega}$在 $\mid\mid\cdot\mid\mid&lt;/em&gt;{\infty}$ 上是$\frac{1}{\gamma}$-smooth.&lt;/p&gt;

&lt;p&gt;通过对 ${\max}_{\Omega}$ 的 $x$ 求偏导即得softmax：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{\prod}_{\Omega}(x) = \frac{\partial {\max}_{\Omega}}{\partial x}=\frac{e^{x/\gamma}}{\sum_{i=1}^d e^{x_i/\gamma}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;其中 $\gamma$越小，输出的 $softmax$就越尖锐。&lt;a href=&quot;https://arxiv.org/abs/1503.02531?context=cs&quot;&gt;Distilling the Knowledge in a Neural Network&lt;/a&gt; 里面也涉及到$\gamma$的设计。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;### 3.2 Sparsemax：&lt;/p&gt;

&lt;p&gt;选择 $\Omega(y)=\frac{1}{2}\mid\mid y\mid\mid^2_2$, 它也被称为Moreau-Yosida正则化常用于近端算子理论。&lt;/p&gt;

&lt;p&gt;由于 $\frac{1}{2}\mid\mid y\mid\mid^2_2$ 在$\mid\mid\cdot\mid\mid_2$ 中是 1-strongly convex，所以在${\max}_{\Omega}$在$\mid\mid\cdot\mid\mid_2$上是$\frac{1}{\gamma}$-smooth.&lt;/p&gt;

&lt;p&gt;由此能得：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{\prod}_{\Omega}(x)=P_{\Delta^d}(x/\gamma) = \arg\min_{y\in \Delta^d}\mid\mid y-x/\gamma\mid\mid^2&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;当$\gamma=1$时，上式就为Sparsemax（softmax的一个稀疏替代）。&lt;/p&gt;

&lt;p&gt;这推导得出：调控 $\gamma$ 可以控制稀疏性。根据sparsemax的论文&lt;a href=&quot;https://arxiv.org/pdf/1602.02068.pdf&quot;&gt;From softmax to sparsemax: A sparse model of attention and multi-label classification&lt;/a&gt;中的公式 $9$可以知道 ${\prod}&lt;em&gt;{\Omega}$ 的雅可比矩阵为:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;J_{ {\prod}_{\Omega}}(x)=\frac{1}{\gamma}J_{P_{\Delta^d}}(x/\gamma)=\frac{1}{\gamma}\big(diag(s)-ss^T/\mid\mid s\mid\mid_1\big)&lt;/script&gt;&lt;br /&gt;
&amp;gt; 其中 $s\in{0,1}^d$ 指示着 ${\prod}&lt;/em&gt;{\Omega}(x)$ 的非$0$元素。&lt;br /&gt;
&amp;gt; &lt;br /&gt;
&amp;gt; ${\prod}_{\Omega}(x)$ 是Lipschitz 连续，处处可导。&lt;br /&gt;
&amp;gt; &lt;br /&gt;
&amp;gt; 详情建议阅读sparsemax的论文。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;## 4. Fusedmax与Oscarmax 新Attention机制&lt;/p&gt;

&lt;p&gt;论文提出 **论点 $1$：如果 $\Omega$ 函数可微，那可以计算出 ${\prod}&lt;em&gt;{\Omega}$ 的雅可比矩阵 .**&lt;br /&gt;
&amp;gt; 论文附录 $A.1$ 已证明，只要提供了$\Omega$的Jacobian和Hessian，那就可以根据论文提供的公式计算出 $J&lt;/em&gt;{ {\prod}_{\Omega}}$ .&lt;/p&gt;

&lt;p&gt;那来一个简单例子吧。&lt;/p&gt;

&lt;h3 id=&quot;squared-p-norms-p-&quot;&gt;4.1. 示例：Squared p-norms（平方 p-范式）&lt;/h3&gt;

&lt;p&gt;Squared p-norms作为单纯形上可微函数的一个有用例子：$\Omega(y)=\frac{1}{2}\mid\mid y\mid\mid^2_p = \big(\sum_{i=1}^d y_i^p \big)^{2/p}$ , 其中 $y\in\Delta^d$ 且 $p\in(1,2]$.&lt;/p&gt;

&lt;p&gt;我们已知 squared p-norm 在$\mid\mid\cdot\mid\mid_p$是strongly convex, 这也指出，当$\frac{1}{p} + \frac{1}{q} = 1$时， ${\max}_{\Omega}$ 在 $\mid\mid\cdot\mid\mid_q$ 是$\frac{1}{\gamma(p-1)}$-smooth 。计算出sq-pnorm-max为：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{\prod}_{\Omega}(x)= \arg\min_{y\in \Delta^d} \frac{\gamma}{2}\mid\mid y\mid\mid^2_p - y^Tx&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;论点$1$ 所需要的梯度和Hessian可以通过 $\nabla\Omega(y)=\frac{y^{p-1}}{\mid\mid y\mid\mid^{p-2}&lt;em&gt;p}$ 以及下式得到所需要的$J&lt;/em&gt;{ {\prod}_{\Omega}}$.&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;H_{\Omega}(y)=diag(d)+ uu^T,\quad where \quad d=\frac{(p-1)}{\mid\mid y\mid\mid^{p-2}_p}y^{p-2} \quad and \quad u=\sqrt{\frac{(2-p)}{\mid\mid y\mid\mid^{2p-2}_p}} y^{ p-1}&lt;/script&gt;&lt;br /&gt;
&amp;gt; sq-pnorm-max 的 $p = 2$ 时就恢复为 sparsemax 一样鼓励稀疏输出。 &lt;br /&gt;
&amp;gt; &lt;br /&gt;
&amp;gt; 但$1&amp;lt;p&amp;lt;2$ 时，$y^&lt;em&gt;=[0,1]$和$y^&lt;/em&gt;=[0,1]$ 间的转换将会更平滑。所以在实验中采用 $p=1.5$ 。详情可以查阅论文中对比图的分析与实验。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;### 4.2. Fusedmax与Oscarmax&lt;/p&gt;

&lt;p&gt;上文已经采用Squared p-norm 例子展示了论点$1$（或说这一套解决方案）的可行性之后，接下论文将提出适合作为Attention机制的可微且$\beta$-strongly convex 的 $\Omega$ 函数。&lt;br /&gt;
&amp;gt; 下面会讲到Fusedmax和Oscarmax，其中会涉及到TV(全变分)和OSCAR(用于回归的八边形收缩和聚类算法)。 &lt;br /&gt;
&amp;gt; &lt;br /&gt;
&amp;gt; TV和OSCAR在文章后面会有单独解释。&lt;/p&gt;

&lt;h4 id=&quot;fusedmax&quot;&gt;Fusedmax&lt;/h4&gt;
&lt;p&gt;当输入是连续且顺序是有一定意义的时（如自然语言），我们希望能&lt;strong&gt;鼓励让连续区域的文本段有着相同的Attention值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;为此，基于&lt;a href=&quot;https://web.stanford.edu/group/SOL/papers/fused-lasso-JRSSB.pdf&quot;&gt;Sparsity and smoothness via the fused lasso&lt;/a&gt;的fused lasso（或称 1-d total variation(TV))，选择$\Omega(y)=\frac{1}{2}\mid\mid y\mid\mid^2_2 + \lambda\sum_{i=1}^{d-1}\mid y_{i+1} - y_i\mid$, 即为强凸项和1-d TV惩罚项的和。 故可以得到：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{\prod}_{\Omega}(x)= \arg\min_{y\in {\Delta}^d}\frac{1}{2}\mid\mid y-x/\gamma\mid\mid^2 + \lambda\sum^{d-1}_{i=1}\mid y_{i+1}- y_i\mid.&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;oscarmax&quot;&gt;Oscarmax&lt;/h4&gt;

&lt;p&gt;由于TV让连续区域聚集（即鼓励连续区域的attention值相等），这样的前提假设太严格，于是作者参考&lt;a href=&quot;https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2007.00843.x&quot;&gt;Simultaneous regression shrinkage, variable selection, and&lt;br /&gt;
supervised clustering of predictors with OSCAR&lt;/a&gt;中的OSCAR惩罚函数，以来鼓励对元素进行聚类，让同一集群的元素它们的Attention值相等。即&lt;strong&gt;鼓励对可能不连续的单词组给予同等重视&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;选择$\Omega(y)=\frac{1}{2}\mid\mid y\mid\mid^2_2 + \lambda\sum_{i&amp;lt;j} \max(\mid y_i\mid,\mid y_j\mid)$， 故可得到：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
{\prod}_{\Omega}(x)= \arg\min_{y\in {\Delta}^d}\frac{1}{2}\mid\mid y-x/\gamma\mid\mid^2 + \lambda\sum_{i&lt;j}\max(\mid y_i\mid,\mid y_j\mid). %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;fusedmaxoscarmax&quot;&gt;4.3. Fusedmax与Oscarmax的计算与其雅可比矩阵&lt;/h3&gt;

&lt;p&gt;根据论文中的论点$2$和论点$3$, 就可得出Fusedmax和Oscarmax分别对应的雅可比矩阵了。&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
[J_{P_{TV}}(x)]_{i,j} =\left\{
             \begin{array}{l}
             \frac{1}{\mid G^*_i\mid}  &amp; if\; j\in G^*_i \\
             0 &amp; o.w. 
             \end{array}\right. %]]&gt;&lt;/script&gt; &lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
[J_{P_{OSC}}(x)]_{i,j} =\left\{
             \begin{array}{l}
             \frac{sign(z^*_i z^*_j)}{\mid G^*_i\mid}  &amp; if\; j\in G^*_i \; and \; z^*_i\neq 0\\
             0 &amp; o.w. 
             \end{array}\right. %]]&gt;&lt;/script&gt; &lt;br /&gt;
&amp;gt; $P_{TV}(x):=\arg\min_{y\in {R}^d}\frac{1}{2}\mid\mid y-x\mid\mid^2 + \lambda\sum^{d-1}&lt;em&gt;{i=1}\mid y&lt;/em&gt;{i+1}- y_i\mid.$&lt;br /&gt;
&amp;gt;$P_{OSC}(x):=\arg\min_{y\in {R}^d}\frac{1}{2}\mid\mid y-x\mid\mid^2 + \lambda\sum_{i&amp;lt;j}\max(\mid y_i\mid,\mid y_j\mid)$&lt;br /&gt;
&amp;gt; &lt;br /&gt;
&amp;gt; $G^&lt;em&gt;_i={j\in [d]:\mid  z^&lt;/em&gt;_i\mid = \mid z^&lt;em&gt;_j\mid }.$ 其中$\mid G^&lt;/em&gt;_i\mid$ 表示 $i$ 组的元素数量。&lt;br /&gt;
&amp;gt; &lt;br /&gt;
&amp;gt; 论文附录 $A.2$ 有详细的证明过程。&lt;br /&gt;
&amp;gt; &lt;br /&gt;
&amp;gt; 论文的附录中还有大量实验结果，可以加深理解。&lt;/p&gt;

&lt;p&gt;来看一个 法语-英语翻译 Attention实验效果：&lt;br /&gt;
&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/fusedmax_oscarmax.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;## 5. TV与OSCAR的简单介绍：&lt;/p&gt;

&lt;h3 id=&quot;tvtotal-variation-&quot;&gt;5.1. TV(Total variation, 全变分)&lt;/h3&gt;

&lt;p&gt;TV(Total variation, 全变分)，也称为全变差，在图像复原中常用到。TV是在一函数其数值变化的差的总和，具体可查阅&lt;a href=&quot;https://zh.wikipedia.org/zh-cn/%E6%80%BB%E5%8F%98%E5%B7%AE&quot;&gt;wiki-Total_variation&lt;/a&gt;或&lt;a href=&quot;https://zh.wikipedia.org/zh-cn/%E6%80%BB%E5%8F%98%E5%B7%AE&quot;&gt;wiki-总变差&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;实值函数ƒ定义在区间$[a, b] \in R$的总变差是一维参数曲线$x \rightarrow ƒ(x) , x \in [a,b]$的弧长。 连续可微函数的总变差，可由如下的积分给出:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;V^a_b(f)=\int^b_a \mid f&#39;(x)\mid \mathrm{d}x&lt;/script&gt;&lt;br /&gt;
任意实值或虚值函数ƒ定义在区间[a,b]上的总变差，由下面公式定义($p$为区间$[a,b]$中的所有分划):&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;V^a_b(f)=sup_P\sum^{n_p -1}_{i=0}\mid f(x_{i+1}) - f(x_{i})\mid&lt;/script&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;TV图解&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;当绿点遍历整个函数时，&amp;lt;p&amp;gt;绿点在y-轴上的投影红点走过的&lt;strong&gt;路程&lt;/strong&gt;&amp;lt;p&amp;gt;就是该函数的总变分TV&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Total_variation.gif&quot; alt=&quot;Total_variation&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;因为细节或假细节（如噪音）区域较多的信号则TV值较大，那假如我们得到观察信号$x_i$, 希望对$x_i$进行去噪，就可以通过引入最小化$x_i$的全变分，得到去噪且保持了图像边缘的图像。即对原复原函数引入TV正则项，如一维去噪：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\min_y \frac{1}{2}\sum_i(x_i-y_i)^2 + \lambda \sum_{i=1}^n\mid y_{i+1} - y_i \mid&lt;/script&gt;&lt;br /&gt;
更多解释可参考&lt;a href=&quot;https://www.zhihu.com/question/47162419&quot;&gt;如何理解全变分（Total Variation，TV）模型？&lt;/a&gt;和&lt;a href=&quot;https://blog.csdn.net/hanlin_tan/article/details/52448803&quot;&gt;浅谈图象的全变分和去噪&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;论文中说Fused Lasso也称为1d-TV ，公式为：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\hat{\beta}_{fused} = {\arg\min}_{\beta}\frac{1}{2}{\mid\mid y-\beta\mid\mid}_2^2 + \lambda \cdot \mid\mid D\beta\mid\mid_1&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;在1维中 : $\hat{\beta}&lt;em&gt;{fused} = {\arg\min}&lt;/em&gt;{\beta}\frac{1}{2}{\mid\mid y-\beta\mid\mid}&lt;em&gt;2^2 + \lambda \cdot \sum&lt;/em&gt;{i=1}^{n-1}\mid\beta_i - \beta_j\mid_1 $ ， 则此时$D$ 为(若n=5)：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\left(
 \begin{matrix}
   1 &amp; -1 &amp; 0 &amp; 0 &amp; 0\\
   0 &amp; 1 &amp; -1 &amp; 0 &amp; 0\\
   0 &amp; 0 &amp; 1 &amp; -1 &amp; 0\\
   0 &amp; 0 &amp; 0 &amp; 1 &amp; -1
  \end{matrix}
  \right) %]]&gt;&lt;/script&gt;&lt;br /&gt;
将上述方法应用在1维数据得到结果如下(图来自&lt;a href=&quot;http://euler.stat.yale.edu/~tba3/stat612/lectures/lec22/lecture22.pdf&quot;&gt;The Generalized Lasso，Lecture 22&lt;/a&gt;）：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Fuse_lasso_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出，数据最终呈现连续区域的聚集，即空间聚集（spatial clutering)，也就得到了稀疏形式的数据表示。 得到更平滑的数据表示，也能防止过拟合的数据表示。&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
  &lt;p&gt;但是TV让连续区域聚集（即鼓励连续区域的值相等），这样的前提假设太严格，于是作者参考OSCAR惩罚函数，以来鼓励对Attention的输出值进行聚集，让同集群的Attention值相等。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;
&lt;p&gt;### 5.2. OSCAR (用于回归的八边形收缩和聚类算法)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2007.00843.x&quot;&gt;Simultaneous regression shrinkage, variable selection, and supervised clustering of predictors with OSCAR&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;OSCAR(用于回归的八边形收缩和聚类算法，octagonal shrinkage and clustering algorithm for regression)可以被解释为同时实现聚类和回归. 是做稀疏和分组变量选择，类似于Elastic Net.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://people.ee.duke.edu/~lcarin/Minhua3.20.09.pdf&quot;&gt;OSCAR-PPT解释&lt;/a&gt;：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{align}
&amp;Penalized Regression一般形式： &amp; \hat{\beta} &amp;  = \min_{\beta}\mid\mid y- x\beta\mid\mid^2_2 \quad s.t. \quad f(\beta)\le t \\
&amp;Ridge Regression: &amp; f(\beta) &amp;=\mid\mid\beta\mid\mid^2_2=\sum^{p}_{j=1}\beta^2_j\\
&amp;LASSO：  &amp; f(\beta) &amp; =\mid\mid\beta\mid\mid_1=\sum^{p}_{j=1}\mid\beta\mid \\
&amp;Group LASSO:  &amp; f(\beta) &amp; =\sum^{G}_{g=1}\mid\mid\beta_g\mid\mid_2\\
&amp;Elastic Net(弹性网络）:  &amp; f(\beta) &amp; =\alpha\mid\mid\beta\mid\mid^2_2+(1-\alpha)\mid\mid\beta\mid\mid_1\\
&amp;OSCAR:  &amp; f(\beta) &amp; =\mid\mid\beta\mid\mid_1 + c\sum_{j &lt; k} \max\{\mid\beta\mid_j,\mid\beta\mid_k\}, L_1与pair-wise L_{\infty}组合。
\end{align} %]]&gt;&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;OSCAR是做稀疏和分组变量选择，类似于Elastic Net.&lt;/li&gt;
  &lt;li&gt;与Group-LASSO相比，它不需要群组结构的先验知识。&lt;/li&gt;
  &lt;li&gt;它比Elastic Net有更强的假设，OSCAR假定：相关变量（correlated variables）的回归系数的绝对值相同。&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Elastic Net&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;OSCAR&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/oscar_elasticnet.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/oscar_oscar.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$L_1$和$L_2$范式组合&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$L_1$和$L_{\infty}$范式组合&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;看上图也就能理解“八边形收缩”这名称了. 该OSCAR基于惩罚最小二乘法，将一些系数收缩至恰好为零。同时这惩罚函数能产生值相同的系数，鼓励相关的预测因子(即指$x_i$)它们对最终结果有着相同的影响，从而形成单个系数表示预测因子群集。&lt;/p&gt;

&lt;p&gt;至于更详细的理解，就阅读下原论文吧&lt;a href=&quot;https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1541-0420.2007.00843.x&quot;&gt;Simultaneous regression shrinkage, variable selection, and supervised clustering of predictors with OSCAR&lt;/a&gt;。&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;## 6. 后语&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;论文中提出新的Attention机制：fusedmax和oscarmax，它们是能被反向传播训练的神经网络所使用。基于论文给出的公式计算即可完成该Attention机制的前向和反向的计算。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;文中的实验都是文本语言方面（textual entailment，machine translation, summarization）， 但如果想用于视觉方面，应该需要适当修改 fusedmax。因为fusedmax所指的连续的区域应当是二维局域图，而非一维连续点（卷积层中）。而oscarmax因为可以对不连续的元素进行Attention值上的聚集，故可以直接应用在图像方面。&lt;/p&gt;

&lt;p&gt;Attention的输出值进行稀疏，这个原因和理由容易理解（即稀疏的优点）。但为什么要对元素进行聚集且赋予相同的Attention值呢？我觉得主要的原因还是防止过拟合的数据表示，即防止Attention机制过拟合。当然，如果翻翻聚类方面的论文或许有更好的解释。&lt;/p&gt;

&lt;p&gt;文中很多公式在其他论文中已证出，想完整地看懂这篇文章，还需要好好把引用的论文理解理解。&lt;br /&gt;
&amp;gt;随便点开都是一屏幕公式推导&lt;/p&gt;

&lt;p&gt;由于我数学方面的功底不好，论文涉及的一些背后知识都是现查现学.&lt;/p&gt;

&lt;p&gt;欢迎讨论指错，轻喷就好 = =。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38897903&quot;&gt;若出现格式问题，可移步查看知乎同款文章：Fusedmax与Oscarmax：稀疏及结构化的Attention正则化框架&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;
</description>
        <pubDate>Sun, 01 Jul 2018 00:00:00 +0800</pubDate>
        <link>http://luonango.github.io/2018/07/01/Fusedmax%E4%B8%8EOscarmax%E7%A8%80%E7%96%8F%E5%8F%8A%E7%BB%93%E6%9E%84%E5%8C%96%E7%9A%84Attention%E6%AD%A3%E5%88%99%E5%8C%96%E6%A1%86%E6%9E%B6/</link>
        <guid isPermaLink="true">http://luonango.github.io/2018/07/01/Fusedmax%E4%B8%8EOscarmax%E7%A8%80%E7%96%8F%E5%8F%8A%E7%BB%93%E6%9E%84%E5%8C%96%E7%9A%84Attention%E6%AD%A3%E5%88%99%E5%8C%96%E6%A1%86%E6%9E%B6/</guid>
        
        <category>Attention</category>
        
        <category>正则化</category>
        
        <category>稀疏</category>
        
        
      </item>
    
      <item>
        <title>CapsulesNet的解析</title>
        <description>&lt;h1 id=&quot;capsulesnet&quot;&gt;CapsulesNet的解析&lt;/h1&gt;

&lt;h2 id=&quot;section&quot;&gt;前言：&lt;/h2&gt;

&lt;p&gt;本文先简单介绍传统CNN的局限性及Hinton提出的Capsule性质，再详细解析Hinton团队近期发布的基于动态路由及EM路由的CapsuleNet论文。&lt;/p&gt;

&lt;h2 id=&quot;hintoncnn&quot;&gt;Hinton对CNN的思考&lt;/h2&gt;

&lt;p&gt;Hinton认为卷积神经网络是不太正确的，它既不对应生物神经系统，也不对应认知神经科学，甚至连CNN本身的目标都是有误的。&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;在生物神经系统上不成立&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;反向传播难以成立。神经系统需要能够精准地求导数，对矩阵转置，利用链式法则，这种解剖学上从来也没有发现这样的系统存在的证据。&lt;/li&gt;
  &lt;li&gt;神经系统含有分层，但是层数不高，而CNN一般极深。生物系统传导在ms量级（GPU在us量级），比GPU慢但效果显著。&lt;/li&gt;
  &lt;li&gt;灵长类大脑皮层中大量存在皮层微柱，其内部含有上百个神经元，并且还存在内部分层。与我们使用的CNN不同，它的一层还含有复杂的内部结构。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cnn&quot;&gt;在认知神经科学上CNN也靠不住脚&lt;/h4&gt;
&lt;p&gt;人会不自觉地根据物体形状建立“坐标框架”(coordinate frame)。并且坐标框架的不同会极大地改变人的认知。人的识别过程受到了空间概念的支配，判断物体是否一样时，我们需要通过旋转把坐标框架变得一致，才能从直觉上知道它们是否一致，但是CNN没有类似的“坐标框架”。如人类判断下图两字母是否一致：&lt;br /&gt;
&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Capsules_net_Mental_rotation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;cnn-1&quot;&gt;CNN的目标不正确&lt;/h4&gt;

&lt;p&gt;先解释下不变性（Invariance)和同变性（Equivariance）。不变性是指物体本身不发生任何变化；同变性指物体可以发生变化，但变化后仍是这种物体。如将MNIST图片中的数字进行平移（该数字形状无变化），就实现了该数字的不变性。如果数字进行了立体的旋转翻转等，但人类仍能识别出这个数字，这就是该数字的同变性。&lt;/p&gt;

&lt;p&gt;显然，我们希望的是CNN能够实现对物体的同变性（Equivariance），虽然CNN在卷积操作时实现了同变性（卷积操作是对视野内的物体进行矩阵转换，实现了视角变换），但主要由于Pooling，从而让CNN引入了不变性。这从而让CNN实现对物体的不变性而不是同变性。&lt;/p&gt;

&lt;p&gt;比如CNN对旋转没有不变性（即旋转后的图片和原图CNN认为是不一样的），我们平时是采用数据增强方式让达到类似意义上的旋转不变性（CNN记住了某图片的各种角度，但要是有个新的旋转角度，CNN仍会出问题）。当CNN对旋转没有不变性时，也就意味着舍弃了“坐标框架”。&lt;/p&gt;

&lt;p&gt;虽然以往CNN的识别准确率高且稳定，但我们最终目标不是为了准确率，而是为了得到对内容的良好表示，从而达到“理解”内容。&lt;/p&gt;

&lt;h2 id=&quot;hintoncapsules&quot;&gt;Hinton提出的Capsules&lt;/h2&gt;

&lt;p&gt;基于上述种种思考，Hinton认为物体和观察者之间的关系（比如物体的姿态），应该由一整套激活的神经元表示，而不是由单个神经元或者一组粗编码（coarse-coded）表示（即一层中有复杂的内部结构）。这样的表示，才能有效表达关于“坐标框架”的先验知识。且构成的网络必须得实现物体同变性。&lt;/p&gt;

&lt;p&gt;这一套神经元指的就是Capsule。Capsule是一个高维向量，用一组神经元而不是一个来代表一个实体。并且它还隐含着所代表的实体出现的概率。&lt;/p&gt;

&lt;p&gt;Hinton认为存在的两种同变性(Equivariance)及capsule的解决方法：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;位置编码（place-coded）：视觉中的内容的位置发生了较大变化，则会由不同的 Capsule 表示其内容。&lt;/li&gt;
  &lt;li&gt;速率编码（rate-coded）：视觉中的内容为位置发生了较小的变化，则会由相同的 Capsule 表示其内容，但是内容有所改变。&lt;/li&gt;
  &lt;li&gt;两者的联系是，高层的 capsule 有更广的域 (domain)，所以低层的 place-coded 信息到高层会变成 rate-coded。&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;dynamic-routing-between-capsules&quot;&gt;第一篇《Dynamic Routing Between Capsules》的解析&lt;/h2&gt;

&lt;p&gt;好的，那让我们看看Hinton 团队2017年10月公布的论文：&lt;a href=&quot;https://arxiv.org/abs/1710.09829&quot;&gt;Dynamic Routing Between Capsules&lt;/a&gt;（Sara Sabour为第一作者）&lt;/p&gt;

&lt;p&gt;官方源代码已发布：&lt;a href=&quot;https://github.com/Sarasra/models/tree/master/research/capsules&quot;&gt;Tensorflow代码&lt;/a&gt; 。不得不提下，由于官方代码晚于论文，论文发布后很多研究者尝试复现其代码，获得大家好评的有&lt;a href=&quot;https://github.com/naturomics/CapsNet-Tensorflow&quot;&gt;HuadongLiao的CapsNet-Tensorflow&lt;/a&gt;、&lt;a href=&quot;https://github.com/XifengGuo/CapsNet-Keras&quot;&gt;Xifeng Guo的CapsNet-Keras&lt;/a&gt;等等。&lt;/p&gt;

&lt;p&gt;该论文中的Capsule是一组神经元（即向量），表示特定类型实体的实例化参数。而其向量的长度表示该实体存在的概率、向量的方向表示实例化的参数。同一层的 capsule 将通过变换矩阵对高层的 capsule 的实例化参数进行预测。当多个预测一致时（文中使用动态路由使预测一致），高层的 capsule 将变得活跃。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;动态路由方法&lt;/h3&gt;

&lt;p&gt;有很多方法实现capsule的总体思路，该论文只展示了动态路由方法（之后不久Hinton用EM-Routing的方法实现capsule的整体思路，相应解析在后面）。&lt;/p&gt;

&lt;p&gt;由于想让Capsule的输出向量的长度，来表示该capsule代表的实体在当前的输入中出现的概率，故需要将输出向量的长度（模长）限制在$[0,1]$。文中采用Squashing的非线性函数作为激活函数来限制模长，令当前层是$j$层，$v_j$为$capsule_j$的输出向量，$s_j$是$capsule_j$的所有输入向量。&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;v_j=\frac{\mid\mid s_j\mid \mid ^2}{1+\mid\mid s_j\mid\mid ^2}\frac{s_j}{\mid\mid s_j\mid \mid }&lt;/script&gt;&lt;br /&gt;
那$s_j$怎么来呢？别急，我们定义一些概念先：&lt;/p&gt;

&lt;p&gt;令$u_i$是前一层(第$i$层）所有$capsule_i$的输出向量，且$\hat{u}&lt;em&gt;{j|i}$是$u_i$经过权重矩阵$W&lt;/em&gt;{ij}$变换后的预测向量。&lt;br /&gt;
那除了第一层，其他层的$s_j$都是前一层所有$capsule_i$的预测向量$\hat{u}&lt;em&gt;{j|i}$的加权和（加权系数为$c&lt;/em&gt;{ij}$）。&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;s_j = \sum_i c_{ij}\hat{u}_{j|i} \quad,\qquad \hat{u}_{j|i} = W_{ij}u_i&lt;/script&gt;&lt;br /&gt;
其中的耦合系数$c_{ij}$就是在迭代动态路由过程中确定的，且每个$capsule_i$与高层所有$capsule_j$的耦合系数$c_{ij}$之和为1。它是通过‘路由softmax’得出：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;c_{ij}=\frac{exp(b_{ij})}{\sum_k exp(b_{ik})}&lt;/script&gt;&lt;br /&gt;
$b_{ij}$可理解为当前$j$层的输出向量$v_j$与前一层所有$capsule_i$的预测向量$\hat{u}_{j|i}$的相似程度，它在动态路由中的迭代公式为：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;b_{ij}=b_{ij}+\hat{u}_{j|i}v_j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;那么，当得到$l$层的$capsule_i$所有输出向量$u_i$，求$l+1$层的输出向量的流程为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;a) 通过权重矩阵$W_{ij}$，将$u_i$变换得到预测向量$\hat{u}_{j&lt;/td&gt;
          &lt;td&gt;i}$。权重矩阵$W$是通过反向传播更新的。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;b) 进入动态路由进行迭代（通常迭代3次就可以得到较好结果）:
    &lt;ul&gt;
      &lt;li&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Capsules_net_6.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;c) 得到第$l+1$ 层$capsule_j$的输出向量$v_j$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以看看&lt;a href=&quot;https://www.jiqizhixin.com/articles/2017-11-05&quot;&gt;机器之心绘制的层级结构图&lt;/a&gt;来加深理解：&lt;br /&gt;
&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/CapsNet_1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;capsule&quot;&gt;Capsule网络结构&lt;/h3&gt;
&lt;p&gt;解决了动态路由的算法流程后，我们再来看下论文设计的简单的网络结构：&lt;br /&gt;
&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Capsules_net_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;第一层ReLU Conv1层的获取&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;普通的卷积层方法，使用256个9×9的卷积核、步幅为1、ReLU作为激活函数，得到256×20×20的张量输出。与前面的输入图片层之间的参数数量为:256×1×9×9+256=20992.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;第二层PrimaryCaps层的获取&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;从普通卷积层构建成Capsule结构的PrimaryCaps层，用了256×32×8个9×9的卷积核，步幅为2，32×8个bias，得到32×8×6×6的张量输出（即32×6×6个元素数为8的capsule）。&lt;/li&gt;
      &lt;li&gt;与前面层之间的参数总量为：256×32×8×9×9+32×8=5308672.（不考虑routing里面的参数）&lt;/li&gt;
      &lt;li&gt;值得注意的是，官方源码中接着对这32×6×6个capsule进行动态路由过程（里面包括了Squashing操作），得到新的输出。而论文中没提及到此处需要加上动态路由过程，导致一些研究人员复现的代码是直接将输出经过Squashing函数进行更新输出（部分复现者已在复现代码中添加了动态路由过程）。&lt;/li&gt;
      &lt;li&gt;PrimaryCaps层的具体构建可查看源码中的layers.conv_slim_capsule函数。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;第三层DigitCaps层的获取&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;从PrimaryCaps层有32&lt;em&gt;6&lt;/em&gt;6=1152个capsule，DigitCaps有10个，所以权重矩阵$W_{ij}$一共有1152×10个，且$W_{ij}=[8×16]$，即$i \in [0,8), j\in[0,16)$。另外还有10*16个偏置值。&lt;/li&gt;
      &lt;li&gt;进行动态路由更新，最终得到10*16的张量输出。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;参数的更新&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;权重矩阵 $W_{ij}、bias$通过反向传播进行更新。&lt;/li&gt;
      &lt;li&gt;动态路由中引入的参数如$c_{ij}、b_{ij}$均在动态路由迭代过程中进行更新。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-3&quot;&gt;损失函数&lt;/h3&gt;
&lt;p&gt;解决了论文设计的网络结构后，我们来看下论文采用损失函数（Max-Margin Loss形式）：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;L_c=T_c \max\big(0,m^+ - \mid\mid v_c\mid\mid\big)^2 + \lambda\big(1-T_c\big) \max\big(0,\mid\mid v_c\mid\mid - m^-\big)^2&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;其中$c$表示类别，$c$存在时，指示函数$T_c=1$,否则$T_c=0$。$m^+、m^-$分别为上边界和下边界，$\mid\mid v_c\mid\mid$为$v_c$的L2范数。论文设置$\lambda=0.5$，降低第二项的loss的系数，防止活泼的（模长较大）capsule倾向于缩小模长，从而防止网络训练差（系数大则求导的数值绝对值大，则第二项loss反馈的更新会更有力）。上下边界一般不为1或0，是为了防止分类器过度自信。&lt;/li&gt;
  &lt;li&gt;总loss值是每个类别的$L_c$的和:  $L=\sum_{c} L_c$&lt;/li&gt;
  &lt;li&gt;该损失函数与softmax区别在于：
    &lt;ul&gt;
      &lt;li&gt;softmax倾向于提高单一类别的预测概率而极力压低其他类别的预测概率，且各类别的预测概率和为1。适用于单类别场景中的预测分类。&lt;/li&gt;
      &lt;li&gt;而此损失函数，要么提高某类别的预测概率（若出现了该类 ），要么压低某类别的预测概率（若未出现该类），不同类别间的预测概率互不干扰，每个类别的预测概率均在$[0,1]$中取值。适用于多类别并存场景中的预测分类。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;section-4&quot;&gt;重构与表征&lt;/h3&gt;

&lt;p&gt;重构的思路很简单，利用DigitCaps中的capsule向量，重新构建出对应类别的图像。文章中使用额外的重构损失来促进 DigitCaps 层对输入数字图片进行编码：&lt;br /&gt;
![](&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Capsules_net_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由于DigitCaps中每个capsule向量都代表着一个实体(数字)，文章采用掩盖全部非正确数字的capsule，留下代表正确数字实体的capsule来重构图片。&lt;/p&gt;

&lt;p&gt;此处的重构损失函数是采用计算在最后的 FC Sigmoid 层采用的输出像素点与原始图像像素点间的欧几里德距离。且在训练中，为了防止重构损失主导了整体损失（从而体现不出Max-Margin Loss作用），文章采用 0.0005 的比例缩小了重构损失。&lt;/p&gt;

&lt;h3 id=&quot;section-5&quot;&gt;实验结果&lt;/h3&gt;

&lt;h4 id=&quot;mnist&quot;&gt;采用MNIST数据集进行分类预测：&lt;/h4&gt;
&lt;p&gt;在此之前，一些研究者使用或不使用集成+数据增强，测试集错误率分别为0.21%和0.57%。而本文在单模型、无数据增强情况下最高达到0.25%的测试集错误率。具体如下图：&lt;br /&gt;
&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Dynamic_Routing_10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;multimnist&quot;&gt;采用MultiMNIST数据集进行重构实验：&lt;/h4&gt;

&lt;p&gt;采用混合数字图片的数据集进行重构，如下图，对一张两数字重叠的图片进行重构，重构后的数字用不同颜色显示在同一张图上。$L:(l_1,l_2)$表示两数字的真实标签，$R:(r_1,r_2)$表示预测出并重构的两数字，带$*$标识的那两列表示重构的数字既不是标签数字也不是预测出的数字（即挑取其他capsule进行重构）。&lt;br /&gt;
&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Dynamic_Routing_11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;## 第二篇《Matrix Capsules with EM routing》的解析&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://openreview.net/pdf?id=HJWLfGWRb&quot;&gt;Matrix Capsules with EM routing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;紧接着上一篇，Hinton以第一作者发布的了这篇论文，现已被ICLR接收。那这一篇与前一篇动态路由Capsule有什么不同呢？&lt;/p&gt;

&lt;p&gt;论文中提出三点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(1). 前一篇采用capsule输出向量(pose vector)的模长作为实体出现的概率，为了保证模长小于1，采用了无原则性质的非线性操作，从而让那些活泼的capsule在路由迭代中被打压。&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;(2).计算两个capsule的一致性（相似度）时，前一篇用两向量间夹角的余弦值来衡量（即指相似程度的迭代：$b_{ij}=b_{ij}+\hat{u}_{j&lt;/td&gt;
          &lt;td&gt;i} v_j$）。与混合高斯的对数方差不同，余弦不能很好区分”好的一致性”和”非常好的一致性”。&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;(3).前一篇采用的pose是长度为$n$的向量，变换矩阵$W_{ij}$具有$n_i&lt;em&gt;n_j$个参数（如$W_{ij}=[8&lt;/em&gt;16], n_i=8,n_j=16$）。 而本文采用的带$n$个元素的矩阵作为pose，这样变换矩阵$W_{ij}$具有$n$个参数（如$n=4*4)$。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从而Hinton设计了新的Capsule的结构：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;结构&lt;/th&gt;
      &lt;th&gt;图示&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;a). 4*4的pose矩阵,表示该capsule代表的实体,对应第(3)点.&lt;br /&gt;&lt;br /&gt;b). 1个激活值,表示该capsule代表实体出现的概率,对应第(1)点.&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Capsules_matrix_7.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;且上一篇采用的是动态路由的方法完成了Capsule网络，而这儿将则采用EM路由算法。这也对应着上述第（2）、（3）点。&lt;/p&gt;

&lt;h3 id=&quot;em-routing&quot;&gt;理解EM Routing前的准备&lt;/h3&gt;
&lt;p&gt;我们先定义下标符号：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$i$: 指$L$层中的某个capsule。&lt;/li&gt;
  &lt;li&gt;$c$: 指$L+1$层中的某个capsule。&lt;/li&gt;
  &lt;li&gt;$h$: 指Pose矩阵中的某维，共16维。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了更好理解EM-Routing算法的过程，我们先理理前期思路：&lt;/p&gt;

&lt;p&gt;与前一篇方法类似，$L$层的$Cpasule_i$的输出($pose$)需要经过矩阵变换$W_{ic}=[4&lt;em&gt;4]$，得到它对$L+1$层的$Capsule_c$的$pose$的投票$V_{ic}$(维度和$pose$一样都是$[4&lt;/em&gt;4]$)之后，才能进入Routing更新。而当$h$为$4*4$中的某一维时，让$V_{ich} = pose_{ih} * W_{ich}$，这样就可以得到$V_{ic}$了，这也对应着上述(3)。&lt;/p&gt;

&lt;p&gt;换种解释说：$L$层的$Capsule_i$要投票给$L+1$层的$Capsule_c$，但是不同的$Capsule_c$可能需要不同变化的$Capsule_i$。所以对于每个$Capsule_c$，$Capsule_i$都有一个转换矩阵$W_{ic}$，$Capsule_i$转换后的$V_{ic}$就称投票值，而$V_{ich}$是指在$V_{ic}$在$h$维（一共4*4=16维）上的值。且变换矩阵$W_{ic}$是反向传播更新的。&lt;/p&gt;

&lt;p&gt;文中对每个Capsule的pose建立混合高斯模型，让pose的每一维都为一个单高斯分布。即$Capsule_c$的pose中的$h$维为一个单高斯模型，$P_{ich}$是指$pose_{ch}$的值为$V_{ich}$的概率。&lt;br /&gt;
令$\mu_{ch}$和$\sigma_{ch}^2$分别为$Capsule_c$在$h$维上的均值和方差，则：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;P_{ich}=\frac{1}{\sqrt{2 \pi \sigma_{ch}^2}}{exp\big({-\frac{(V_{ich}-\mu_{ch})^2}{2\sigma_{ch}^2}}}\big)&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;ln(P_{ich})=  -\frac{(V_{ich}-\mu_{ch})^2}{2\sigma_{ch}^2} - ln(\sigma_{ch})-\frac{ln(2\pi)}{2}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;再令$r_i$为$Capsule_i$的激活值，就可以写出该$Capsule_c$在$h$维度上的损失$cost_{ch}$:&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;cost_{ch}=\sum_i -r_i ln(P_{ich})=\frac{\sum_i{r_i\sigma_{ch}^2}}{2\sigma_{ch}^2} + \big(ln(\sigma_{ch})+ \frac{ln(2\pi)}{2}\big)\sum_i r_i=\big(ln(\sigma_{ch}+k)\big)\sum_i r_i&lt;/script&gt;&lt;br /&gt;
值得注意的是，这里的$\sum_i$ 并不是指$L$层的所有$capsule_i$，而是指可以投票给$Capsule_c$的$Capsule_i$，这点之后会解释。 另外式子中的$k$是一个常数，它可以通过反向传播进行更新，这个在后面也会提到。&lt;/p&gt;

&lt;p&gt;$Capsule_c$的激活值可用下面公式得出：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;a_c=logistic\big(\lambda\big(b_c-\sum_h cost_{ch}\big)\big)&lt;/script&gt;&lt;br /&gt;
其中$-b_c$代表$Capsule_c$在$h$维上的代价均值，它可以通过反向传播进行更新。而$\lambda$是温度倒数，是超参，我们可以在训练过程中逐步改变它的值。文章中的logistic函数采用sigmoid函数。&lt;/p&gt;

&lt;p&gt;好的，我们现在整理下在EM Routing要用的参数：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$Capsule_i$、$Capsule_c$&lt;/td&gt;
      &lt;td&gt;分别指为$L$层、$L+1$层的某个$Capsule$&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$W_{ic}$&lt;/td&gt;
      &lt;td&gt;$Capsule_i$投票给$capsule_c$前的变换矩阵，通过反向传播进行更新&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$V_{ic}$&lt;/td&gt;
      &lt;td&gt;$Capsule_i$经过矩阵变换后准备给$capsule_c$的投票值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$P_{ic}$&lt;/td&gt;
      &lt;td&gt;$Capsule_i$的投票值在$Capsule_c$中的混合高斯概率&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$cost_{ch}$&lt;/td&gt;
      &lt;td&gt;$Capsule_c$在$h$维度上的损失&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$\mu_{ch}$、$\sigma_{ch}^2$&lt;/td&gt;
      &lt;td&gt;Capsulec在h维上的均值和方差&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$k$&lt;/td&gt;
      &lt;td&gt;$cost_{ch}$式子中的一个常数，通过反向传播进行更新&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$a_c$&lt;/td&gt;
      &lt;td&gt;$Capsule_c$的激活值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$-b_c$&lt;/td&gt;
      &lt;td&gt;$Capsule_c$在$h$维上的代价均值，通过反向传播进行更新&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$\lambda$&lt;/td&gt;
      &lt;td&gt;温度倒数，是超参，在迭代过程中逐步增大它的值&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;###　EM Routing的流程：&lt;/p&gt;

&lt;h4 id=&quot;section-6&quot;&gt;总流程：&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/EM_ROUTING_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;梳理符号：
    &lt;ul&gt;
      &lt;li&gt;$R_{ic}$表示$Capsule_i$给$Capsule_c$投票的加权系数&lt;/li&gt;
      &lt;li&gt;$M_c$、$S_c$ 表示$Capsule_c$的Pose的期望和方差&lt;/li&gt;
      &lt;li&gt;$size(L+1)$ 表示$Capsule_i$要投票给$L+1$层的Capsule的总数，即与$Capsule_i$有关系的$Capsule_c$的总数&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;传入$L$层的所有$Capsule_i$的激活值$a$和矩阵转换后的投票值$V$，输出$L+1$层所有$Capsule_c$的激活值$a^{‘}$和Pose最终的期望值。&lt;/li&gt;
  &lt;li&gt;对投票加权系数初始化后就进行EM算法迭代（一般迭代3次）：
    &lt;ul&gt;
      &lt;li&gt;对每个$Capsule_c$，M-step得到它的Pose的期望和方差&lt;/li&gt;
      &lt;li&gt;对每个$Capsule_i$，E-step中得到它更新后的对所有$Capsule_c$投票的加权系数。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;再次提醒，这里$Capsule_i$不是投票给所有而是部分$Capsule_c$。此处的”所有“是为了表述方便。具体理由之后会解释。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;m-step&quot;&gt;分析M-Step步骤:&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/EM_ROUTING_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;梳理符号：
    &lt;ul&gt;
      &lt;li&gt;$cost_h$即为$cost_{ch}$，是$Capsule_c$在$h$维度上的损失.&lt;/li&gt;
      &lt;li&gt;$\beta_v$即为$cost_{ch}$式子中的一个常数k（前面提及过），通过反向传播进行更新.&lt;/li&gt;
      &lt;li&gt;$\beta_a$即为$Capsule_c$在$h$维上的代价均值$-b_c$的负数(前面提及过)&lt;/li&gt;
      &lt;li&gt;$\lambda$即为温度倒数。是超参，在迭代中将逐步增大它的值（前面提及过），通过反向传播进行更新&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;对于某$Capsule_c$，传入所有$Capsule_i$对它的投票加权系数$R_{:c}$、所有$Capsule_i$的激活值$a$、所有$Capsule_i$矩阵转换后对它的投票值$V_{:c:}$，输出该$Capsule_c$的激活值以及pose期望方差。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;e-step&quot;&gt;分析E-Step步骤:&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/EM_ROUTING_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;梳理符号：
    &lt;ul&gt;
      &lt;li&gt;$p_c$即为$P_{ic}$，是$Capsule_i$的投票值在$Capsule_c$中的混合高斯概率，前面提及过。&lt;/li&gt;
      &lt;li&gt;$r$即为$r_i$， 是$Capsule_i$给所有$Capsule_c$投票的加权系数&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;对于某$Capsule_i$， 传入它对所有$Capsule_c$的投票$V_i$、所有$Capsule_c$的激活值以及pose的均值和方差，得到它更新后的对所有$Capsule_c$投票的加权系数$r_i$。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;经过一轮的公式符号轰炸，我们就明白了EM-Routing的整体流程。&lt;/p&gt;

&lt;h3 id=&quot;matrix-capsules-&quot;&gt;Matrix Capsules 网络模型&lt;/h3&gt;

&lt;p&gt;接下来我们要看下Hinton设计的Matrix Capsule的网络模型：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/EM_ROUTING_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由于涉及到Capsule的卷积操作，此处先定义一些概念，以ConvCaps1层为例子，在ConvCaps1层中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;含有C个channel，每个channel含有6*6=36个capsule。&lt;/li&gt;
  &lt;li&gt;不同的channel含有不同的类型capsule，同一channel的capsule的类型相同但位置不同。&lt;/li&gt;
  &lt;li&gt;任一个capsule均有6*6-1=35个相同类型的capsule，均有C-1个位置相同的capsule。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;relu-conv1&quot;&gt;第一层ReLU Conv1的获取：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;普通的卷积层，使用A个5×5的卷积核、步幅为2、ReLU作为激活函数，得到A×14×14的张量输出。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;primarycaps&quot;&gt;第二层PrimaryCaps的获取:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;从普通卷积层构建成Capsule结构的PrimaryCaps层，用了A×B×(16+1)个1×1的卷积核，步幅为1，得到B×14×14个pose和B&lt;em&gt;14&lt;/em&gt;14个激活值，即有B&lt;em&gt;14&lt;/em&gt;14个capsule。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;convcaps1&quot;&gt;第三层ConvCaps1的获取：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;此处将PrimaryCaps层（即$L$层）中的$Capsule_i$的pose进行矩阵转换后，得到对应的投票矩阵$V$。将$V$和全部$Capsule_i$的激活值传入RM-Routing中，即可得到C&lt;em&gt;6&lt;/em&gt;6个$Capsule_c$的pose及激活值。&lt;/li&gt;
  &lt;li&gt;此处是Capsule卷积操作，卷积核大小为K，步幅为2。
    &lt;ul&gt;
      &lt;li&gt;对于$L+1$层的某个$Capsule_c$，需要得到投票给它的那些$Capsule_i$的投票矩阵$V_{:c}$
        &lt;ul&gt;
          &lt;li&gt;在$L$层只有K×K&lt;em&gt;B个$Capsule_i$投票给该$Capsule_c$，对这K×K&lt;/em&gt;B个$Capsule_i$的pose分别进行矩阵转换，即可得到投票矩阵$V_{ic}$&lt;/li&gt;
          &lt;li&gt;这里有K&lt;em&gt;K&lt;/em&gt;B&lt;em&gt;C个转换矩阵$W_{ic}$，每个$W_{ic}$是4&lt;/em&gt;4的矩阵（或说16维的向量）。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;这两层间转换矩阵$W_{ic}$共有：(K&lt;em&gt;K&lt;/em&gt;B)&lt;em&gt;C&lt;/em&gt;6&lt;em&gt;6&lt;/em&gt;个 （而不是14&lt;em&gt;14&lt;/em&gt;B&lt;em&gt;C&lt;/em&gt;6*6).&lt;/li&gt;
      &lt;li&gt;与普通二维卷积一样，不过卷积的乘法操作改为EM-Routing。即被卷积的是$L$层的所有$Capsule_i$的投票矩阵$V_i$和激活值，卷积结果是C&lt;em&gt;6&lt;/em&gt;6个$Capsule_c$的pose及激活值。
        &lt;ul&gt;
          &lt;li&gt;每个$L+1$层的$Caspule_c$都采用capsule卷积（EM-Routing）对应$L$层的K&lt;em&gt;K&lt;/em&gt;B个$Capsule_i$，从而得到该$Caspule_c$的pose和激活值。&lt;/li&gt;
          &lt;li&gt;对于$L$层的中心位置的B个$Capsule_i$，它们每个$Capsule_i$，都只投票给卷积时卷积核滑过它们的对应的$Capsule_c$（共K&lt;em&gt;K&lt;/em&gt;C个）。而$L$层的边缘位置的每个$Capsule_i$投票给$L+1$层的$Capsule_c$个数将小于K&lt;em&gt;K&lt;/em&gt;C个。如$L$层最左上位置的B个$Capsule_i$，它们只能投给$L+1$层最左上角的C个$Capsule_c$（只有$L+1$层的这个位置执行卷积时候卷积核才滑过$L$层最左上角）&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;convcaps2&quot;&gt;第四层ConvCaps2的获取：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;capsule卷积层，与ConvCaps1一样的操作。&lt;/li&gt;
  &lt;li&gt;采用的卷积核K=3，步幅=1 。得到D&lt;em&gt;4&lt;/em&gt;4个capsule的pose与激活值。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;class-capsules&quot;&gt;第五层Class Capsules的获取：&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;从capsule卷积层到最后一层的操作，和前面的做法不同。
    &lt;ul&gt;
      &lt;li&gt;相同类型（即同一channels）的capsule共享转换矩阵，所以两层间共有D&lt;em&gt;E个转换矩阵$W_j$，每个$W_j$是4&lt;/em&gt;4的矩阵（或说16维的向量）。&lt;/li&gt;
      &lt;li&gt;拉伸后的扁长层（Class Capsules层）无法表达capsule的位置信息，而前面ConvCaps2层的每个$capsule_i$都有对应的位置信息。为了防止位置信息的丢失，作者将每个$Capsule_i$的位置信息（即坐标）分别加到它们的投票矩阵$V_ij$的一二维上。随着训练学习，共享转换矩阵$W_j$能将$V_ij$的一二维与$Capsule_i$的位置信息联系起来，从而让Class Capsules层的$Capsule_j$的pose的一二维携带位置信息。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;得到E个capsule， 每个capsule的pose表示对应calss实体，而激活值表示该实体存在的概率。&lt;/li&gt;
  &lt;li&gt;这样就可以单独拿出capsule的激活值做概率预测，拿capsule的pose做类别实体重构了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;整体的Matrix Capsules网络模型就梳理完成了。现在还剩下损失函数了。&lt;/p&gt;

&lt;h3 id=&quot;spread-loss&quot;&gt;损失函数：传播损失(Spread Loss):&lt;/h3&gt;

&lt;p&gt;为了使训练过程对模型的初始化以及超参的设定没那么敏感，文中采用传播损失函数来最大化被激活的目标类与被激活的非目标类之间的概率差距。a_t表示target的激活值，a_i表示Class_Capsules中除t外第i个的激活值：&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;L_i=\big(\max \big(0,m-(a_t-a_i)\big)\big)^2 , \quad  L=\sum_{i\neq t} L_i&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;m将从0.2的小幅度开始，在训练期间将其线性增加到0.9，避免无用胶囊的存在。那为什么要这样做呢？ &lt;br /&gt;
小编的理解是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当模型训练得挺好时候（中后期），每个激活值a_i的比较小而a_t比较大。此时m需要设置为接近1的数值。设置m为0.9而不是1，这是为了防止分类器过度自信，是要让分类器更专注整体的分类误差。&lt;/li&gt;
  &lt;li&gt;当模型初步训练时候，很多capsules起的作用不大，最终的激活值a_i和a_t相差不大，若此时m采用较大值如0.9,就会掩盖了(a_t-a_i)在参数更新的作用，而让m主导了参数更新。
    &lt;ul&gt;
      &lt;li&gt;比如两份参数W1和W2对同样的样本得到的$a_t-a_i$值有：$W1_{a_t-a_i} &amp;lt; W2_{a_t-a_i}$ ，那显然W2参数优于W1参数，即W1参数应该得到较大幅度的更新。但由于处于模型初步阶段，$W_{a_t-a_i}$值很小，若此时m较大，则m值主导了整体loss。换句话说，m太大会导致W1和W2参数更新的幅度相近，因为$a_t-a_i$被忽略了。&lt;/li&gt;
      &lt;li&gt;不过参数的更新幅度取决于对应的导数，由于此处的spread loss含有平方，所以m值的设置会关系到参数的导数，从而影响到参数更新的幅度 （有些loss由于公式设计问题会导致从loss看不出参数更新的幅度，如若此处将Spread loss的平方去掉，参数的更新就和m无关了）。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;section-7&quot;&gt;实验结果&lt;/h3&gt;

&lt;p&gt;作者采用smallNORB数据集（具有5类玩具的灰度立体图片：飞机、汽车、卡车、人类和动物）上进行了实验。选择smallNORB作为capsule网络的基准，因为它经过精心设计，是一种纯粹的形状识别任务，不受上下文和颜色的混淆，但比MNIST更接近自然图像。下图为在不同视角上的smallNORB物体图像：&lt;br /&gt;
&lt;img src=&quot;https://github.com/luonango/luonango.github.io/raw/master/img/pictures/EM_ROUTING_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;该smallNORB数据集，CNN中的基准线是：测试集错误率5.2%，参数总量4.2M。而作者使用小型的capsule网络（A=64, B = 8, C = D = 16，参数总量68K），达到2.2%的测试集错误率，这也击败了当前最好的记录。&lt;/p&gt;

&lt;p&gt;作者还实验了其他数据集。采用上图的Matrix Capsules网络及参数，在MNIST上就达到了0.44％的测试集错误率。如果让A=256，那在Cifar10上的测试集错误率将达到11.9％.&lt;/p&gt;

&lt;p&gt;文章后面还讨论了在对抗样本上，capsule模型和传统卷积模型的性能。实验发现，在白箱对抗攻击时，capsule模型比传统的卷积模型更能抵御攻击。而在黑箱对抗攻击时，两种模型差别不大。感兴趣的话可以看看论文中对这部分实验的设置及分析。&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;section-8&quot;&gt;参考链接：&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.09829&quot;&gt;Dynamic Routing Between Capsules&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://openreview.net/pdf?id=HJWLfGWRb&quot;&gt;Matrix Capsules with EM routing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/29435406&quot;&gt;浅析 Hinton 最近提出的 Capsule 计划&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kndrck.co/posts/capsule_networks_explained/&quot;&gt;Capsule Networks Explained&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jiqizhixin.com/articles/2017-11-05&quot;&gt;先读懂CapsNet架构然后用TensorFlow实现：全面解析Hinton的提出的Capsule&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.jiqizhixin.com/articles/capsule-implement-sara-sabour-Feb02&quot;&gt;Capsule官方代码开源之后，机器之心做了份核心代码解读&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30970675&quot;&gt;CapsulesNet 的解析及整理&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jhui.github.io/2017/11/14/Matrix-Capsules-with-EM-routing-Capsule-Network/&quot;&gt;Understanding Matrix capsules with EM Routing (Based on Hinton’s Capsule Networks)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/Sarasra/models/tree/master/research/capsules&quot;&gt;Dynamic Routing官方源代码-Tensorflow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/naturomics/CapsNet-Tensorflow&quot;&gt;Dynamic Routing:HuadongLiao的CapsNet-Tensorflow&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/XifengGuo/CapsNet-Keras&quot;&gt;Dynamic Routing:Xifeng Guo的CapsNet-Keras&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</description>
        <pubDate>Thu, 01 Feb 2018 00:00:00 +0800</pubDate>
        <link>http://luonango.github.io/2018/02/01/CapsulesNet/</link>
        <guid isPermaLink="true">http://luonango.github.io/2018/02/01/CapsulesNet/</guid>
        
        <category>CNN</category>
        
        <category>图像分类识别</category>
        
        <category>Capsule网络</category>
        
        
      </item>
    
      <item>
        <title>图像分割的传统方法</title>
        <description>
&lt;hr /&gt;
&lt;p&gt;layout:     post&lt;br /&gt;
title:      图片分割的传统方法&lt;br /&gt;
subtitle:   &lt;br /&gt;
date:       2017-11-01&lt;br /&gt;
author:     BY&lt;br /&gt;
header-img: img/post-bg-ios9-web.jpg&lt;br /&gt;
catalog: true&lt;br /&gt;
tags:&lt;br /&gt;
    - 图像分割&lt;br /&gt;
    - 传统方法&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;section&quot;&gt;图片分割的传统方法&lt;/h1&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;section-1&quot;&gt;&lt;strong&gt;图像分割概述&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;根据灰度、颜色、纹理、和形状等特征将图像进行划分区域，让区域间显差异性，区域内呈相似性。主要分割方法有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;基于阈值的分割&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;基于边缘的分割&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;基于区域的分割&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;基于图论的分割&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;基于能量泛函的分割&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;section-2&quot;&gt;&lt;strong&gt;基于阈值的分割方法&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;参考： &lt;a href=&quot;http://www.cnblogs.com/wangduo/p/5556903.html&quot;&gt;基于阈值的图像分割方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;阈值法的基本思想是基于图像的灰度特征来计算一个或多个灰度阈值，并将图像中每个像素的灰度值与阈值相比较，最后将像素根据比较结果分到合适的类别中。因此，该类方法最为关键的一步就是按照某个准则函数来求解最佳灰度阈值。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;固定阈值分割&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;固定某像素值为分割点。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;直方图双峰法&lt;/strong&gt;：
    &lt;ul&gt;
      &lt;li&gt;Prewitt 等人于六十年代中期提出的直方图双峰法(也称 mode 法) 是典型的全局单阈值分割方法。该方法的基本思想是：假设图像中有明显的目标和背景，则其灰度直方图呈双峰分布，当灰度级直方图具有双峰特性时，选取两峰之间的谷对应的灰度级作为阈值。如果背景的灰度值在整个图像中可以合理地看作为恒定，而且所有物体与背景都具有几乎相同的对比度，那么，选择一个正确的、固定的全局阈值会有较好的效果.算法实现：找到第一个峰值和第二个峰值,再找到第一和第二个峰值之间的谷值，谷值就是那个阀值了。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;迭代阈值图像分割&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;1．统计图像灰度直方图,求出图象的最大灰度值和最小灰度值，分别记为ZMAX和ZMIN，令初始阈值T0=(ZMAX+ZMIN)/2；&lt;/li&gt;
      &lt;li&gt;2． 根据阈值TK将图象分割为前景和背景，计算小于TO所有灰度的均值ZO，和大于TO的所有灰度的均值ZB。&lt;/li&gt;
      &lt;li&gt;3． 求出新阈值TK+1=(ZO+ZB)/2；&lt;/li&gt;
      &lt;li&gt;4． 若TK==TK+1，则所得即为阈值；否则转2，迭代计算。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;自适应阈值图像分割&lt;/strong&gt;:&lt;br /&gt;
    有时候物体和背景的对比度在图像中不是处处一样的，普通阈值分割难以起作用。这时候可以根据图像的局部特征分别采用不同的阈值进行分割。只要我们将图像分为几个区域，分别选择阈值，或动态地根据一定邻域范围选择每点处的阈值，从而进行图像分割。
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;大津法 OTSU （最大类间方差法）&lt;/strong&gt;：
        &lt;ul&gt;
          &lt;li&gt;日本学者大津在1979年提出的自适应阈值确定方法。 按照图像的灰度特性，将图像分为背景和目标两部分。背景和目标之间的类间方差越大,说明构成图像的2部分的差别越大,当部分目标错分为背景或部分背景错分为目标都会导致2部分差别变小。因此,使类间方差最大的分割意味着错分概率最小。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;均值法&lt;/strong&gt;:
        &lt;ul&gt;
          &lt;li&gt;把图像分成m*n块子图，求取每一块子图的灰度均值就是所有像素灰度值之和除以像素点的数量，这个均值就是阈值了。这种方法明显不比大津法好，因为均值法和大津法都是从图像整体来考虑阈值的，但是大津法找了一个类间方差最大值来求出最佳阈值的；这两种方法子图越多应该分割效果会好一点，但效率可能会变慢&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;最佳阈值&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;阈值选择需要根据具体问题来确定，一般通过实验来确定。如对某类图片，可以分析其直方图等。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;section-3&quot;&gt;&lt;strong&gt;基于边缘的分割方法&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;参考： &lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8532106&quot;&gt;图像分割之（一）概述&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;图像中两个不同区域的边界线上连续的像素点的集合，是图像局部特征不连续性的反映，体现了灰度、颜色、纹理等图像特性的突变。通常情况下，基于边缘的分割方法指的是基于灰度值的边缘检测，它是建立在边缘灰度值会呈现出阶跃型或屋顶型变化这一观测基础上的方法。阶跃型边缘两边像素点的灰度值存在着明显的差异，而屋顶型边缘则位于灰度值上升或下降的转折处。正是基于这一特性，可以使用微分算子进行边缘检测，即使用一阶导数的极值与二阶导数的过零点来确定边缘，具体实现时可以使用图像与模板进行卷积来完成。&lt;/li&gt;
  &lt;li&gt;边缘角点和兴趣点的检测器有：
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Canny边缘检测器&lt;/strong&gt;：
        &lt;ul&gt;
          &lt;li&gt;将图像P模糊化，然后与一堆正交微分滤波器（如Prewitt滤波器）做卷积生成分别包括水平和垂直方向上的导数的图像H和V，对像素(i,j)计算其梯度方向和幅度。若幅度超过临界值就分配一条边缘（此处称为阈值法，但效果不佳）。canny使用非极大抑制的方法对那些不需要响应的进行删除。&lt;a href=&quot;&quot;&gt;《计算机视觉：模型、学习和推理》第13章&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Harris角点检测器&lt;/strong&gt;：
        &lt;ul&gt;
          &lt;li&gt;对每个点周围的水平方向垂直方向的据ubu梯度进行考虑。目的在于找到图像中亮度在两个方向上均发生变化的点，而非一个方向（一条边缘）或者零个方向（平坦区域）。Harris角点检测器是基于对图像结构张量的决策。&lt;a href=&quot;&quot;&gt;《计算机视觉：模型、学习和推理》第13章&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;SIFT检测器&lt;/strong&gt;:
        &lt;ul&gt;
          &lt;li&gt;尺度不变特征转换，检测是用来识别兴趣点的第二中方法。不同与Harris角点检测器，SIFT将尺度和方向与结果中的兴趣点相关联。为了找到兴趣点，，交替使用多种算子。&lt;a href=&quot;&quot;&gt;《计算机视觉：模型、学习和推理》第13章&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;SURF检测器&lt;/strong&gt; *
        &lt;ul&gt;
          &lt;li&gt;SIFT的改进版。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;section-4&quot;&gt;&lt;strong&gt;基于区域的分割方法&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;参考：&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8532106&quot;&gt;图像分割之（一）概述&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;按照图像的相似性准则划分为不同区域块。主要有种子区域生长法、区域分裂合并法、分水岭法等。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;种子区域生长法&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;根据统一物体区域的像素相似性来聚集像素点达到区域生长的方法。其中由一组表示不同区域的种子像素开始，逐步合并种子周围相似的像素从而扩大区域。直到无法合并像素点或小领域为止。其中区域内的相似性的度量可用平均灰度值、纹理、颜色等等信息。关键在于选择初始种子像素及生长准则。最早的区域生长图像分割方法是由Levine等人提出。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;区域分裂合并法&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;区域分裂合并法（Gonzalez，2002），确定分裂合并的准则，然后将图像任意分成若干互不相交的区域，按准则对这些区域进行分裂合并。它可用于灰度图像分割及纹理图像分割。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分水岭法&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;分水岭法（Meyer，1990）是一种基于拓扑理论的数学形态学的分割方法，其基本思想是把图像看作是测地学上的拓扑地貌，图像中每一点像素的灰度值表示该点的海拔高度，每一个局部极小值及其影响区域称为集水盆，而集水盆的边界则形成分水岭。该算法的实现可以模拟成洪水淹没的过程，图像的最低点首先被淹没，然后水逐渐淹没整个山谷。当水位到达一定高度的时候将会溢出，这时在水溢出的地方修建堤坝，重复这个过程直到整个图像上的点全部被淹没，这时所建立的一系列堤坝就成为分开各个盆地的分水岭。分水岭算法对微弱的边缘有着良好的响应，但图像中的噪声会使分水岭算法产生过分割的现象&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;section-5&quot;&gt;&lt;strong&gt;基于图论的分割方法&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;参考：&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8532106&quot;&gt;图像分割之（一）概述&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此类方法把图像分割问题与图的最小割（min cut）问题相关联。首先将图像映射为带权无向图G=&amp;lt;V，E&amp;gt;，图中每个节点N∈V对应于图像中的每个像素，每条边∈E连接着一对相邻的像素，边的权值表示了相邻像素之间在灰度、颜色或纹理方面的非负相似度。而对图像的一个分割s就是对图的一个剪切，被分割的每个区域C∈S对应着图中的一个子图。而分割的最优原则就是使划分后的子图在内部保持相似度最大，而子图之间的相似度保持最小。基于图论的分割方法的本质就是移除特定的边，将图划分为若干子图从而实现分割。目前所了解到的基于图论的方法有GraphCut，GrabCut和Random Walk等。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8532111&quot;&gt;&lt;strong&gt;GraphCut 图割&lt;/strong&gt;&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;参考：
        &lt;ul&gt;
          &lt;li&gt;Boykov Y Y, Jolly M P. Interactive graph cuts for optimal boundary &amp;amp; region segmentation of objects in N-D images[C]// IEEE International Conference on Computer Vision. IEEE Computer Society, 2001:105.&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8532111&quot;&gt;图像分割之（二）Graph Cut（图割）&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;非常有用和流行的能量优化算法，在计算机视觉领域普遍应用于前背景分割（Image segmentation）、立体视觉（stereo vision）、抠图（Image matting）等。&lt;/li&gt;
      &lt;li&gt;将一幅图像分为目标和背景两个不相交的部分，那就相当于完成了图像分割。&lt;/li&gt;
      &lt;li&gt;此类方法把图像分割问题与图的最小割（min cut）问题相关联。最小割把图的顶点划分为两个不相交的子集S和T。这两个子集就对应于图像的前景像素集和背景像素集。可以通过最小化图割来最小化能量函数得到。能量函数由区域项（regional term）和边界项（boundary term）构成。&lt;/li&gt;
      &lt;li&gt;整个流程的限制是：
        &lt;ul&gt;
          &lt;li&gt;算法基于灰度图；&lt;/li&gt;
          &lt;li&gt;需要人工标注至少一个前景点和一个背景点；&lt;/li&gt;
          &lt;li&gt;结果为硬分割结果，未考虑边缘介于0~1之间的透明度。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20255114&quot;&gt;&lt;strong&gt;GrabCut 分割和抠图&lt;/strong&gt;&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;参考：
        &lt;ul&gt;
          &lt;li&gt;Rother C, Kolmogorov V, Blake A. “GrabCut”: interactive foreground extraction using iterated graph cuts[J]. Acm Transactions on Graphics, 2004, 23(3):309-314.&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20255114&quot;&gt;读《”GrabCut” – Interactive Foreground Extraction using Iterated Graph Cuts》&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8534954&quot;&gt;图像分割之（三）从Graph Cut到Grab Cut&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;是Graphcut图隔的改进版，是迭代的GraphCut。改进包括：
        &lt;ul&gt;
          &lt;li&gt;将基于灰度分布的模型替换为高斯混合模型（Gaussian Mixture Model，GMM）以支持彩色图片;&lt;/li&gt;
          &lt;li&gt;将能一次性得到结果的算法改成了『强大的』迭代流程；将用户的交互简化到只需要框选前景物体即可。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;与Graph Cut不同处：
        &lt;ul&gt;
          &lt;li&gt;Graph Cut的目标和背景的模型是灰度直方图，Grab Cut取代为RGB三通道的混合高斯模型GMM;&lt;/li&gt;
          &lt;li&gt;Graph Cut的能量最小化（分割）是一次达到的，而Grab Cut取代为一个不断进行分割估计和模型参数学习的交互迭代过程;&lt;/li&gt;
          &lt;li&gt;Graph Cut需要用户指定目标和背景的一些种子点，但是Grab Cut只需要提供背景区域的像素集就可以了。也就是说你只需要框选目标，那么在方框外的像素全部当成背景，这时候就可以对GMM进行建模和完成良好的分割了。即Grab Cut允许不完全的标注（incomplete labelling）。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;彩色像素值的稀疏问题比灰度图要严重得多（256 vs 17M），所以，继续使用histogram是不现实的，需要信息压缩得更好一点的模型，作者在这里参考前人，对前景和背景各建了K=5的高斯混合模型。&lt;/li&gt;
      &lt;li&gt;GrabCut是按颜色分布和边缘对比度来分割图片的，对一些常见的与此原则相悖的图片，效果确实不好。比如前景人物的帽子、鞋、墨镜，通常颜色跟前景主体有较大区别；再如前景中的孔，有可能由于颜色区分和边缘的对比度不足，导致边缘的惩罚占上风，而没有扣出来背景。所以，GrabCut还是保留了人工修正的操作，定义了两种标记：绝对是背景和可能是前景。对分割错误人工修正后，分割还是可以比较准确的。对自然场景图片的分割，比Bayes matte等方法得到的边缘明显看起来舒服得多。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;section-6&quot;&gt;&lt;strong&gt;基于能量泛函的分割方法&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;参考：
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8532106&quot;&gt;图像分割之（一）概述&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;该类方法主要指的是活动轮廓模型（active contour model）以及在其基础上发展出来的算法，其基本思想是使用连续曲线来表达目标边缘，并定义一个能量泛函使得其自变量包括边缘曲线，因此分割过程就转变为求解能量泛函的最小值的过程，一般可通过求解函数对应的欧拉(Euler．Lagrange)方程来实现，能量达到最小时的曲线位置就是目标的轮廓所在。&lt;/p&gt;

&lt;p&gt;活动轮廓模型逐渐形成了不同的分类方式，较常见的是根据曲线演化方式的不同，将活动轮廓模型分为基于边界、基于区域和混合型活动轮廓模型。按照模型中曲线表达形式的不同，活动轮廓模型可以分为两大类：参数活动轮廓模型（parametric active contour model）和几何活动轮廓模型（geometric active contour model）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;参数活动轮廓模型（parametric active contour model）&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;参数活动轮廓模型基于Lagrange框架，直接以曲线的参数化形式来表达曲线，最具代表性的是由Kasset a1(1987)所提出的Snake模型。该类模型在早期的生物图像分割领域得到了成功的应用，但其存在着分割结果受初始轮廓的设置影响较大以及难以处理曲线拓扑结构变化等缺点，此外其能量泛函只依赖于曲线参数的选择，与物体的几何形状无关，这也限制了其进一步的应用。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Snake模型&lt;/strong&gt;：
        &lt;ul&gt;
          &lt;li&gt;参考：
            &lt;ul&gt;
              &lt;li&gt;Michael Kass et al. Snakes: Active contour models. International Journal of Computer Vision, pages 321-331, 1987.&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/zouxy09/article/details/8712287&quot;&gt;图像分割之（五）活动轮廓模型之Snake模型简介&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/VictoriaW/article/details/59110318&quot;&gt;计算机视觉之图像分割——Snake模型(1译文)&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;在处理如边缘检测、角点识别、动态跟踪以及立体匹配等任务上非常成功。&lt;/li&gt;
          &lt;li&gt;SNAKE模型就是一条可变形的参数曲线及相应的能量函数，以最小化能量目标函数为目标，控制参数曲线变形，具有最小能量的闭合曲线就是目标轮廓。模型的形变受到同时作用在模型上的许多不同的力所控制，每一种力所产生一部分能量，这部分能量表示为活动轮廓模型的能量函数的一个独立的能量项。&lt;/li&gt;
          &lt;li&gt;基本Snakes模型的能量函数由三项组成，弹性能量和弯曲能量合称内部能量（内部力），用于控制轮廓线的弹性形变，起到保持轮廓连续性和平滑性的作用。而第三项代表外部能量，也被称为图像能量，表示变形曲线与图像局部特征吻合的情况。内部能量仅仅跟snake的形状有关，而跟图像数据无关。而外部能量仅仅跟图像数据有关。在某一点的α和β的值决定曲线可以在这一点伸展和弯曲的程度。最终对图像的分割转化为求解能量函数Etotal(v)极小化（最小化轮廓的能量）。在能量函数极小化过程中，弹性能量迅速把轮廓线压缩成一个光滑的圆，弯曲能量驱使轮廓线成为光滑曲线或直线，而图像力则使轮廓线向图像的高梯度位置靠拢。基本Snakes模型就是在这3个力的联合作用下工作的。&lt;/li&gt;
          &lt;li&gt;snake相对于经典的特征提取方法有以下优点：
            &lt;ul&gt;
              &lt;li&gt;通过正确设置和项前系数，可交互方式控制snake;&lt;/li&gt;
              &lt;li&gt;容易操控，因为图像力是以直观的方式表现;&lt;/li&gt;
              &lt;li&gt;在寻找最小能量状态的时候它们是自主的和自适应的;&lt;/li&gt;
              &lt;li&gt;可以通过在图像能量函数中加入高斯平滑而对图像尺度敏感;&lt;/li&gt;
              &lt;li&gt;可以用于跟踪时间或者空间维度上的动态目标。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;snake的缺点：
            &lt;ul&gt;
              &lt;li&gt;初始位置不同使得结果不同;&lt;/li&gt;
              &lt;li&gt;经常陷入局部最小状态，这也许可以通过使用模拟退火技术来克服，代价就是计算时间增加;&lt;/li&gt;
              &lt;li&gt;在最小化整个轮廓路径上的能量过程中经常忽略微小特征;&lt;/li&gt;
              &lt;li&gt;精度由能量最小化技术中使用的收敛标准控制；更高的精度要求更严格的收敛标准，因此需要更长的计算时间。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;ASM(Active Shape Model)&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;参考：
            &lt;ul&gt;
              &lt;li&gt;Cootes T F, Taylor C J. Active Shape Models — ‘Smart Snakes’[M]// BMVC92. Springer London, 1992:266–275.&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/watkinsong/article/details/8891071&quot;&gt;ASM(Active Shape Model) 主动形状模型总结&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;ASM（主动形状模型）是建立在PDM（点分布模型）的基础上，通过训练图像样本获取训练图像样本的特征点分布的统计信息，并且获取特征点允许存在的变化方向，实现在目标图像上寻找对应的特征点的位置。训练样本需要手动的标记所有的特征点的位置，记录特征点的坐标，并且计算每一个特征点对应的局部灰度模型作为局部特征点调整用的特征向量。在将训练好的模型放在目标图像上，寻找每一个特征点的下一个位置的时候，采用局部灰度模型寻找在当前特征点指定方向上局部灰度模型马氏距离最小的特征点作为当前特征点即将移动到的位置，称为suggested point, 找到所有的suggested points就可以获得一个搜索的suggested shape, 然后将当前的模型通过调整参数使得当前的模型最可能相似的调整到suggest shape，重复迭代直到实现收敛。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;AAM(Active Appearance Models)&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;参考：
            &lt;ul&gt;
              &lt;li&gt;Cootes T F, Edwards G J, Taylor C J. Active Appearance Models[C]// European Conference on Computer Vision. Springer Berlin Heidelberg, 1998:484-498.&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/carson2005/article/details/8196996&quot;&gt;AAM（Active Appearance Model）算法介绍&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;ASM是基于统计形状模型的基础上进行的，而AAM则是在ASM的基础上，进一步对纹理（将人脸图像变形到平均形状而得到的形状无关图像）进行统计建模，并将形状和纹理两个统计模型进一步融合为表观模型。&lt;/li&gt;
          &lt;li&gt;AAM模型相对于ASM模型的改进为：
            &lt;ul&gt;
              &lt;li&gt;使用两个统计模型融合 取代 ASM的灰度模型。&lt;/li&gt;
              &lt;li&gt;主要对特征点的特征描述子进行了改进，增加了描述子的复杂度和鲁棒性&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;CLM(Constrained local model)有约束的局部模型&lt;/strong&gt;
        &lt;ul&gt;
          &lt;li&gt;参考：
            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/marvin521/article/details/11489453&quot;&gt;机器学习理论与实战（十六）概率图模型04&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;CLM是有约束的局部模型，ASM也属于CLM的一种。CLM通过初始化平均脸的位置，然后让每个平均脸上的特征点在其邻域位置上进行搜索匹配来完成人脸点检测。整个过程分两个阶段：模型构建阶段和点拟合阶段。模型构建阶段又可以细分两个不同模型的构建：
            &lt;ul&gt;
              &lt;li&gt;形状模型构建: 对人脸模型形状进行建模，说白了就是一个ASM的点分布函数（PDM），它描述了形状变化遵循的准则.&lt;/li&gt;
              &lt;li&gt;Patch模型构建: 对每个特征点周围邻域进行建模，也就说建立一个特征点匹配准则，怎么判断特征点是最佳匹配.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;几何活动轮廓模型（geometric active contour model）&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;参考：
        &lt;ul&gt;
          &lt;li&gt;·S.Osher,J.A.Sethian,Fronts propagating with curvature dependent speed:algorithms basedon Hamilton-Jacobi formulations.Journal of Computational Physics,1988,79:12—49&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;http://blog.csdn.net/vast_sea/article/details/8196507&quot;&gt;图像分割___图像分割方法综述&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;几何活动轮廓模型的曲线运动过程是基于曲线的几何度量参数而非曲线的表达参数，因此可以较好地处理拓扑结构的变化，并可以解决参数活动轮廓模型难以解决的问题。而水平集（Level Set）方法（Osher，1988）的引入，则极大地推动了几何活动轮廓模型的发展，因此几何活动轮廓模型一般也可被称为水平集方法。&lt;/li&gt;
      &lt;li&gt;几何活动轮廓模型(Geometric Active Contours Model)是以曲线演化理论和水平集方法为理论基础,继参数活动轮廓模型后形变模型的又一发展,是图像分割和边界提取的重要工具之一。相对于参数活动轮廓模型,几何活动轮廓模型具有很多优点,如可以处理曲线的拓扑变化、对初始位置不敏感、具有稳定的数值解等.&lt;/li&gt;
      &lt;li&gt;几何活动轮廓模型又可分为基于边界的活动轮廓模型、基于区域的活动轮廓模型。基于边界的活动轮廓模型主要依赖图像的边缘信息控制曲线的运动速度。在图像边缘强度较弱或是远离边缘的地方，轮廓曲线运动速度较大，而在图像边缘强度较强的地方，轮廓曲线运动速度较小甚至停止，使得最终的轮廓曲线运动到边缘位置.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;传统方法的收集大致结束。&lt;/p&gt;

&lt;p&gt;End …&lt;/p&gt;

&lt;hr /&gt;
</description>
        <pubDate>Wed, 01 Nov 2017 00:00:00 +0800</pubDate>
        <link>http://luonango.github.io/2017/11/01/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95/</link>
        <guid isPermaLink="true">http://luonango.github.io/2017/11/01/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%9A%84%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95/</guid>
        
        
      </item>
    
  </channel>
</rss>
