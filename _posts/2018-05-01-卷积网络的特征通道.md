---
layout:     post
title:      卷积网络的特征通道
subtitle:   论文技术分享：feature maps
date:       2018-05-01
author:     BY
header-img: img/tag-bg-o.jpg
catalog: true
tags:
    - CNN
    - 网络结构
    - feature maps

---

# 卷积网络的特征通道
---
从实际的角度出发，由于深度神经网络受到大量矩阵运算的限制，往往需要海量存储及计算资源。削减神经网络中卷积单元的冗余是解决这个问题的重要研究之一，它可并分为空间（spatial）及通道（channel）两个方向。

先谈谈通道上的解决方法。

---

# 从Alexnet说起：

|Alexnet|
|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/AlexNet_1.png)|
|单个GTX 580 GPU只有3GB内存,不能满足当时的参数规模|
|将网络分布在两个GPU上，每个GPU中放置一半核（或神经元），GPU间的通讯只在某些层进行|
|如第3层的核需要从第2层中所有核映射输入。然而，第4层的核只需要从第3层中位于同一GPU的那些核映射输入|
|即为双通道网络结构，减少了大量的连接参数消耗|

---
# Inception系列也是多通道

|Inception_v1|Inception_v2-v3|Xception|
|-|-|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Inception_v1_2.png)|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Inception_v2_3.png)|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Xception_1.png)|

Xception中主要采用**depthwise separable convolution**技术（mobileNets中提出，深度学习模型加速网络的核心技术）。

假设输入的是A个特征图，最终输出B个特征图。Xception的卷积就是将传统的卷积操作分成两步：

- 然后用A个1*1的卷积核正常卷积生成的A个特征图。求和，最后生成A个特征图
- 用B个3*3卷积核，一对一卷积B个特征图。不求和，直接拼生成B个特征图；

##　mobileNets与Xception使用depthwise的区别：

- mobileNets中与Xception中的执行顺序刚好相反。
- 在mobileNet中主要就是为了降低网络的复杂度。
- 在Xception中作者加宽了网络，使得参数数量和Inception v3差不多，然后在这前提下比较性能。Xception目的不在于模型压缩，而是提高性能。

---

# 2017_ICCV_微软的交错组卷积（IGC，Interleaved Group Convolution）

## ICG模块

|交错组卷积模块：含两个组卷积过程|
|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Interleaved_Group_Convolutions_for_Deep_Neural_Networks_1.png)|
|第一次组卷积：不同组的卷积不存在交互，不同组的输出通道并不相关。|
|第二次组卷积：让不同组的通道相关联。每组的输入通道均来自第一组输出的不同的组的通道（交错组成）|

## 特点：
- 从通道角度出发，解决了神经网络基本卷积单元中的冗余问题。
- 可以在无损性能的前提下，缩减模型、提升计算速度，有助于深度网络在**移动端**的部署.


## 极端和最优分配下的分析

- Xception 是特例：
    + 如果第一次组的每组只有一个输出通道，那么就变成了特殊的组卷积，即 channel-wise convolution，第二次组卷积成为 1X1 的卷积，这与 Xception 相似（顺序相反）。
- 普通卷积：
    + 如果第一次组卷积过程里仅有一组，那么这个过程就变成了普通卷积，第二次组卷积过程则相当于分配给每个通过一个不同的权重。
- 分配情况：
    + 极端情况下:网络的性能会随着通道数及组数的变化而变化
    + 最优性能配置点存在于两个极端情况之间。

---
# 2017_Face++的通道随机分组ShuffleNet

## 模块构造

|**Pointwise组卷积、Channel-Shuffle 和 Depthwise** 组成的模块|
|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/ShuffleNet_An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices_1.png)|
|GConv 指组卷积。 group convolution|
|Pointwise：卷积核为1*1的组卷积(不采用组卷积则计算量太大）。 pointwise group convolution|
|Depthwise：前面提过，先分别组卷积，再1×1卷积核一起卷积。 depthwise separable convolution|
|Channel Shuffle: 将通道洗牌，交错合并组的分块|

|基于ShuffleNet的ResNet|
|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/ShuffleNet_An_Extremely_Efficient_Convolutional_Neural_Network_for_Mobile_Devices_2.png)|
|a图是普通Residual block|
|b图中将Residual block用：**Pointwise组卷积+ Shuffle + 3×3的Depthwise + Pointwise组卷积** 替代|
|c图是实验采用的Residual block|

## 特点：

- 采用 **Channel-Shuffle、Pointwise组卷积 和 Depthwise** 来修改原来的ResNet单元
- Pointwise组卷积和Depthwise主要为了减少了计算量
- 与交错组卷积IGC单元（Interleaved Group Convolution）相似。
- 大幅度降低网络计算量，专用于计算能力非常有限的移动端设备.
- 超越mobilenet、媲美AlexNet的准确率.


该论文和IGC在shuffle上相似，且两者都是17年7月份提交。IGC未引用该文，而此文中提到：

- 最近，另一项并行工作[41]也采用这个思想进行两阶段卷积。然而，[41]没有**专门调查**通道shuffle本身的有效性和在小模型设计上的使用。
- Such “random shuffle” operation has different purpose and been seldom exploited later. Very recently, another concurrent work[41] also adopt this idea for a two-stage convolution. However,[41] did not **specially investigate** the effectiveness of channel shuffle itself and its usage in tiny model design.

---

# 考虑通道的不平等关系SENet (2017_ImageNet冠军)


## 模块构造

|Squeeze-and-Excitation 模块|
|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Squeeze-and-Excitation_Networks_1.jpg)|
|图中输入是X，有$c_1$特征通道。经过一系列卷积变换后，得$c_2$个大小为$w×h$的通道（map）|
|**Squeeze**： 进行特征压缩，每个二维通道变为一个实数，如图得$1×1×c_2$.它们代表相应的特征通道的全局分布.|
|**Excitation**: 学习特征通道间的相关性。根据输入，调节各通道的权重|
|**Reweight**: 以对应的通道权重，乘回对应通道，完成对原始特征的重标定|

## 部署示例

|SE_Inception图示|SE_ResNet图示|
|-|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Squeeze-and-Excitation_Networks_4.png)|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Squeeze-and-Excitation_Networks_5.png)|

##　实验情况：增加小的计算消耗，获得大的性能提升

|||
|-|-|
|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Squeeze-and-Excitation_Networks_3.png)|![](https://github.com/luonango/luonango.github.io/raw/master/img/pictures/Squeeze-and-Excitation_Networks_6.jpg)|


## 特点：
- 考虑特征通道间的关系，动态调整各通道的特征响应值
- 构造简单、容易被部署。增加很小的计算消耗，获得高的性能提升
- 或许可用于辅助网络修剪/压缩的工作

---

# 参考

- 2012-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks
- 2016-Xception: Deep Learning with Depthwise Separable Convolutions
- 2017-Interleaved Group Convolutions for Deep Neural Networks
- 2017-ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices
- 2017-Squeeze-and-Excitation Networks

---

### 小想法：

在组通道网络中，采用SENet思想，对组通道进行加权（而非单通道）。让SENet为一个特例（组为单通道）。

---
